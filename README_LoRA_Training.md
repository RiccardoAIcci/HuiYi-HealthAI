# MiniMind2-Small LoRAå¾®è°ƒè„šæœ¬

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„MiniMind2-Smallæ¨¡å‹LoRAå¾®è°ƒè„šæœ¬ï¼Œæ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ŒåŒ…å«å®Œæ•´çš„è®­ç»ƒæµç¨‹å’Œæ—¥å¿—è®°å½•åŠŸèƒ½ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- âœ… **è‡ªåŠ¨æ¨¡å‹ä¸‹è½½**: ä½¿ç”¨ModelScope SDKè‡ªåŠ¨ä¸‹è½½MiniMind2-PyTorchæ¨¡å‹
- âœ… **æ•°æ®é›†åˆå¹¶**: æ”¯æŒæŒ‰æ¯”ä¾‹åˆå¹¶ä»»åŠ¡æ•°æ®å’Œè‡ªè®¤çŸ¥æ•°æ®
- âœ… **LoRAå¾®è°ƒ**: ä½¿ç”¨PEFTåº“è¿›è¡Œé«˜æ•ˆçš„LoRAå¾®è°ƒ
- âœ… **è®­ç»ƒç›‘æ§**: é›†æˆWeights & Biasesè¿›è¡Œè®­ç»ƒè¿‡ç¨‹ç›‘æ§
- âœ… **å‚æ•°å¯é…ç½®**: æ”¯æŒå‘½ä»¤è¡Œå‚æ•°é…ç½®æ‰€æœ‰è®­ç»ƒå‚æ•°
- âœ… **å®Œæ•´æ—¥å¿—**: è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—å’Œæ—¶é—´ç»Ÿè®¡

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

### Pythonç‰ˆæœ¬
- Python 3.9+

### ç¡¬ä»¶è¦æ±‚
- GPU: æ¨èä½¿ç”¨NVIDIA GPU (æ”¯æŒCUDA)
- å†…å­˜: è‡³å°‘16GB RAM
- å­˜å‚¨: è‡³å°‘10GBå¯ç”¨ç©ºé—´

### ä¾èµ–åŒ…
```bash
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–åŒ…åŒ…æ‹¬:
- torch >= 2.0.0
- transformers >= 4.35.0
- peft >= 0.6.0
- accelerate >= 0.20.0
- wandb >= 0.16.0
- modelscope >= 1.9.0

## ğŸ“ æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®åº”ä¸ºJSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼Œç»“æ„å¦‚ä¸‹ï¼š

```json
{"conversations": [{"role": "user", "content": "ç”¨æˆ·é—®é¢˜"}, {"role": "assistant", "content": "åŠ©æ‰‹å›ç­”"}]}
```

ä¾‹å¦‚ï¼š
```json
{"conversations": [{"role": "user", "content": "ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ"}, {"role": "assistant", "content": "æˆ‘å«æ…§åŒ»å°åŠ©ï¼Œæ˜¯ä¸€åAIåŠ©æ‰‹ã€‚"}]}
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬ä½¿ç”¨

```bash
python minimind_lora_finetune.py \
    --lora_name "my_chatbot_lora" \
    --task_data "./dataset/medical_data_formatted.jsonl" \
    --identity_data "./dataset/medical_identity.jsonl" \
    --epochs 20 \
    --batch_size 4 \
    --learning_rate 1e-4 \
    --use_wandb \
    --wandb_project "my_minimind_project"
```

### 2. å¿«é€Ÿæµ‹è¯•

```bash
python simple_train_example.py
```

### 3. å®Œæ•´å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--lora_name` | str | `medical_chatbot_lora` | LoRAæ¨¡å‹åç§° |
| `--task_data` | str | `./dataset/medical_data_formatted.jsonl` | ä»»åŠ¡æ•°æ®è·¯å¾„ |
| `--identity_data` | str | `./dataset/medical_identity.jsonl` | è‡ªè®¤çŸ¥æ•°æ®è·¯å¾„ |
| `--merged_data` | str | `./dataset/merged_training_data.jsonl` | åˆå¹¶åæ•°æ®è·¯å¾„ |
| `--out_dir` | str | `./out` | è¾“å‡ºç›®å½• |
| `--epochs` | int | `10` | è®­ç»ƒè½®æ¬¡ |
| `--batch_size` | int | `4` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `1e-4` | å­¦ä¹ ç‡ |
| `--max_length` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_wandb` | flag | `False` | ä½¿ç”¨Weights & Biases |
| `--wandb_project` | str | `minimind_medical_chatbot` | W&Bé¡¹ç›®åç§° |
| `--ratio` | int | `3` | ä»»åŠ¡æ•°æ®ä¸è‡ªè®¤çŸ¥æ•°æ®æ¯”ä¾‹ |
| `--skip_download` | flag | `False` | è·³è¿‡æ¨¡å‹ä¸‹è½½ |
| `--skip_merge` | flag | `False` | è·³è¿‡æ•°æ®åˆå¹¶ |

## ğŸ“Š è®­ç»ƒæµç¨‹

### 1. æ¨¡å‹ä¸‹è½½é˜¶æ®µ
```
ğŸ”„ å¼€å§‹ä¸‹è½½MiniMind2-PyTorchæ¨¡å‹...
âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: /path/to/model
```

### 2. æ•°æ®å‡†å¤‡é˜¶æ®µ
```
ğŸ”„ å¼€å§‹åˆå¹¶æ•°æ®é›† (æ¯”ä¾‹ 3:1)...
ğŸ“Š ä»»åŠ¡æ•°æ®: 150000 æ¡
ğŸ“Š è‡ªè®¤çŸ¥æ•°æ®: 96 æ¡
âœ… æ•°æ®åˆå¹¶å®Œæˆ: 150096 æ¡æ•°æ®ä¿å­˜åˆ° ./dataset/merged_training_data.jsonl
```

### 3. æ¨¡å‹è®­ç»ƒé˜¶æ®µ
```
ğŸš€ å¼€å§‹LoRAè®­ç»ƒ...
ğŸ’» ä½¿ç”¨è®¾å¤‡: cuda
ğŸ“‹ è®­ç»ƒå‚æ•°:
  - LoRAåç§°: medical_chatbot_lora
  - è®­ç»ƒè½®æ¬¡: 20
  - æ‰¹æ¬¡å¤§å°: 4
  - å­¦ä¹ ç‡: 1e-4
ğŸ”„ åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...
âœ… æ¨¡å‹åŠ è½½å®Œæˆ
ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: 26.5M
ğŸ“Š å¯è®­ç»ƒå‚æ•°: 0.67M / 26.5M (2.53%)
ğŸ”¥ å¼€å§‹è®­ç»ƒ...
```

### 4. è®­ç»ƒå®Œæˆ
```
âœ… æ¨¡å‹ä¿å­˜åˆ°: ./out/medical_chatbot_lora
â±ï¸ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: 45.2 åˆ†é’Ÿ
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### Weights & Biasesé›†æˆ

è„šæœ¬æ”¯æŒä½¿ç”¨Weights & Biasesè¿›è¡Œè®­ç»ƒç›‘æ§ï¼š

1. è®¾ç½®W&Bè´¦å·ï¼š
```bash
wandb login
```

2. å¯ç”¨W&Bç›‘æ§ï¼š
```bash
python minimind_lora_finetune.py --use_wandb --wandb_project "my_project"
```

### ç›‘æ§æŒ‡æ ‡

- è®­ç»ƒæŸå¤±æ›²çº¿
- å­¦ä¹ ç‡å˜åŒ–
- è®­ç»ƒæ—¶é—´ç»Ÿè®¡
- æ¨¡å‹å‚æ•°ç»Ÿè®¡

## ğŸ”§ é«˜çº§é…ç½®

### LoRAå‚æ•°è°ƒæ•´

å¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„LoRAé…ç½®æ¥è°ƒæ•´å¾®è°ƒæ•ˆæœï¼š

```python
def setup_lora_config(lora_r: int = 8,        # LoRA rankï¼Œè¶Šå¤§æ¨¡å‹å®¹é‡è¶Šå¤§
                      lora_alpha: int = 32,    # LoRA alphaï¼Œå½±å“å­¦ä¹ å¼ºåº¦
                      lora_dropout: float = 0.1):  # LoRA dropoutï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
```

### ç›®æ ‡æ¨¡å—é…ç½®

é»˜è®¤LoRAåº”ç”¨äºæ³¨æ„åŠ›æœºåˆ¶çš„æŠ•å½±å±‚ï¼š
```python
target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- ç¡®ä¿è®­ç»ƒæ•°æ®è´¨é‡é«˜
- ä¿æŒè‡ªè®¤çŸ¥æ•°æ®å’Œä»»åŠ¡æ•°æ®çš„å¹³è¡¡
- å»ºè®®è‡ªè®¤çŸ¥æ•°æ®å æ€»æ•°æ®çš„5-10%

### 2. è¶…å‚æ•°è°ƒä¼˜
- å­¦ä¹ ç‡ï¼šå»ºè®®ä»1e-4å¼€å§‹å°è¯•
- æ‰¹æ¬¡å¤§å°ï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´
- è®­ç»ƒè½®æ¬¡ï¼šé€šå¸¸10-30è½®å³å¯

### 3. ç›‘æ§è®­ç»ƒ
- ä½¿ç”¨W&Bç›‘æ§æŸå¤±å˜åŒ–
- æ³¨æ„é˜²æ­¢è¿‡æ‹Ÿåˆ
- å®šæœŸè¯„ä¼°æ¨¡å‹æ•ˆæœ

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **å†…å­˜ä½¿ç”¨**: è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå ç”¨å¤§é‡GPUå†…å­˜ï¼Œå»ºè®®ä½¿ç”¨è‡³å°‘8GBæ˜¾å­˜çš„GPU
2. **æ•°æ®æ ¼å¼**: ç¡®ä¿æ•°æ®ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼
3. **è·¯å¾„è®¾ç½®**: ç¡®ä¿æ‰€æœ‰è·¯å¾„æ­£ç¡®ï¼Œç‰¹åˆ«æ˜¯æ•°æ®æ–‡ä»¶è·¯å¾„
4. **ç¯å¢ƒé…ç½®**: ç¡®ä¿CUDAç¯å¢ƒæ­£ç¡®é…ç½®

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   - å‡å°batch_size
   - å‡å°max_length
   - ä½¿ç”¨gradient_accumulation_steps

2. **æ•°æ®åŠ è½½é”™è¯¯**
   - æ£€æŸ¥JSONLæ–‡ä»¶æ ¼å¼
   - ç¡®è®¤æ–‡ä»¶ç¼–ç ä¸ºUTF-8
   - éªŒè¯JSONè¯­æ³•æ­£ç¡®æ€§

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ç¡®è®¤ModelScopeè®¿é—®æ­£å¸¸
   - éªŒè¯ç£ç›˜ç©ºé—´å……è¶³

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- åˆ›å»ºIssue
- å‘é€é‚®ä»¶
- å‚ä¸è®¨è®º

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªApache License 2.0è®¸å¯è¯ã€‚ 